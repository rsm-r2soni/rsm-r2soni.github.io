[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rishabh Soni",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Analysis of Cars\n\n\n\n\nYour Name\nApr 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\nYour Name\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "HW1/hw1_questions.html",
    "href": "HW1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "HW1/hw1_questions.html#introduction",
    "href": "HW1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "HW1/hw1_questions.html#data",
    "href": "HW1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "HW1/hw1_questions.html#experimental-results",
    "href": "HW1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "HW1/hw1_questions.html#simulation-experiment",
    "href": "HW1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Let’s investigate the relationship between fuel efficiency (mpg) and engine displacement (disp) from the mtcars dataset. Those variables have a correlation of -0.85.\n\n\nHere is a plot:\n\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Here is a plot:\n\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "projects/project2/hw1_questions.html",
    "href": "projects/project2/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe authors conducted a large-scale natural field experiment by mailing over 50,000 fundraising letters to previous donors of a politically active nonprofit organization. Individuals were randomly assigned to a control group or one of several treatment groups. The treatment groups received letters offering a matching grant that varied in size (e.g., $25k, $50k, $100k), matching ratio ($1:$1, $2:$1, $3:$1), and suggested donation amount (based on their highest previous contribution).\nThis experiment allowed the researchers to isolate the causal effects of financial incentives on both the probability of donating and the amount donated. Their goal was to understand whether increasing the effective “value” of a donation would motivate more people to give — and whether bigger matches further increased this effect.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project2/hw1_questions.html#introduction",
    "href": "projects/project2/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe authors conducted a large-scale natural field experiment by mailing over 50,000 fundraising letters to previous donors of a politically active nonprofit organization. Individuals were randomly assigned to a control group or one of several treatment groups. The treatment groups received letters offering a matching grant that varied in size (e.g., $25k, $50k, $100k), matching ratio ($1:$1, $2:$1, $3:$1), and suggested donation amount (based on their highest previous contribution).\nThis experiment allowed the researchers to isolate the causal effects of financial incentives on both the probability of donating and the amount donated. Their goal was to understand whether increasing the effective “value” of a donation would motivate more people to give — and whether bigger matches further increased this effect.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project2/hw1_questions.html#data",
    "href": "projects/project2/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nlibrary(haven) \n\ndf &lt;- read_dta(\"/home/jovyan/Desktop/Marketing Analytics/projects/project2/karlan_list_2007.dta\") \n\n\n\nReading the Data\nWe use the dataset made available by the authors, which contains over 50,000 observations corresponding to individual donors who received various fundraising letter treatments.\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nTo evaluate whether random assignment was successful, we begin by testing whether the number of months since the last donation (mrm2) differs across treatment and control groups.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndf_clean &lt;- df %&gt;% filter(!is.na(mrm2))\n\n\n\nT-test\n\nlibrary(broom) \n\nWarning: package 'broom' was built under R version 4.4.3\n\ntidy(t.test(mrm2 ~ treatment, data = df_clean))\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1  -0.0137      13.0      13.0    -0.120   0.905    33394.   -0.238     0.211\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\n\n\nLinear regression\n\nsummary(lm(mrm2 ~ treatment, data = df_clean)) \n\n\nCall:\nlm(formula = mrm2 ~ treatment, data = df_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.012  -9.012  -5.012   6.002 154.988 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 12.99814    0.09353 138.979   &lt;2e-16 ***\ntreatment    0.01369    0.11453   0.119    0.905    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.08 on 50080 degrees of freedom\nMultiple R-squared:  2.851e-07, Adjusted R-squared:  -1.968e-05 \nF-statistic: 0.01428 on 1 and 50080 DF,  p-value: 0.9049\n\n\nBoth the t-test and the regression confirm that there is no statistically significant difference in the number of months since last donation (mrm2) between the treatment and control groups.\nThis supports the validity of the experimental design and aligns with Table 1 in Karlan & List (2007), which also shows balanced covariates. These results justify interpreting treatment effects causally in subsequent analyses."
  },
  {
    "objectID": "projects/project2/hw1_questions.html#experimental-results",
    "href": "projects/project2/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\nWe begin by visualizing the proportion of people who donated in each group, followed by statistical testing using a t-test, linear regression, and a probit model to confirm the results shown in Tables 2a and 3 of Karlan & List (2007).\nThis shows the percentage of people who donated by treatment group.\n\nlibrary(ggplot2) \n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\ndf %&gt;% group_by(treatment) %&gt;% summarise(response_rate = mean(gave)) %&gt;% ggplot(aes(x = factor(treatment), y = response_rate, fill = factor(treatment))) + geom_bar(stat = \"identity\") + labs(x = \"Group\", y = \"Proportion Donated\", title = \"Donation Rate by Treatment\") + theme_minimal() \n\n\n\n\n\n\n\n\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.) t-test ::: {.cell}\nlibrary(broom) \n\ntidy(t.test(gave ~ treatment, data = df)) \n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 -0.00418    0.0179    0.0220     -3.21 0.00133    36577. -0.00673  -0.00163\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n::: Linear Regression\n\nsummary(lm(gave ~ treatment, data = df)) \n\n\nCall:\nlm(formula = gave ~ treatment, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02204 -0.02204 -0.02204 -0.01786  0.98214 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.017858   0.001101  16.225  &lt; 2e-16 ***\ntreatment   0.004180   0.001348   3.101  0.00193 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1422 on 50081 degrees of freedom\nMultiple R-squared:  0.000192,  Adjusted R-squared:  0.0001721 \nF-statistic: 9.618 on 1 and 50081 DF,  p-value: 0.001927\n\n\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\nlibrary(margins) \nprobit_model &lt;- glm( gave ~ treatment, data = df, family = binomial(link = \"probit\") ) \n\nThe results show that the treatment group had a significantly higher probability of donating compared to the control group. This finding is confirmed through the t-test, linear regression, and probit model, all of which show a positive and statistically significant treatment effect.\nThese results replicate the patterns seen in Tables 2a and 3 of Karlan & List (2007). They support the conclusion that matching donations are an effective nudge for charitable giving, likely by increasing the perceived impact of a donor’s contribution.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nTo assess whether larger match ratios increase the likelihood of donation, I compare donation rates across 1:1, 2:1, and 3:1 match conditions using both t-tests and regression models.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8? ::: {.cell}\ntreat_only &lt;- df %&gt;% filter(treatment == 1) \n\nt1_vs_2 &lt;- t.test(gave ~ ratio2, data = treat_only %&gt;% filter(ratio3 == 0))\n\nt1_vs_3 &lt;- t.test(gave ~ ratio3, data = treat_only %&gt;% filter(ratio2 == 0)) \n\ntidy(t1_vs_2)\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 -0.00188    0.0207    0.0226    -0.965   0.335    22225. -0.00571   0.00194\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\ntidy(t1_vs_3) \n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 -0.00198    0.0207    0.0227     -1.02   0.310    22215. -0.00582   0.00185\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n::: ### Interpretation\nThe t-tests compare donation response rates among treatment group members who received different match ratios: 1:1, 2:1, and 3:1. The results show that the differences in response rates between 1:1 and 2:1, and between 1:1 and 3:1, are not statistically significant at the 5% level.\nThis indicates that while being offered a matching donation does increase the likelihood of giving (as shown earlier), increasing the match from 1:1 to 2:1 or 3:1 does not further increase the likelihood of donating. These findings support the conclusion in Karlan & List (2007) that larger match ratios had no additional impact on participation.\nIn short, donors are responsive to the presence of a match, but not to how generous it is.\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\n\ndf &lt;- df %&gt;% \nmutate(ratio1 = ifelse(ratio2 == 0 & ratio3 == 0, 1, 0)) \ntreat_df &lt;- df %&gt;% filter(treatment == 1) \nmodel_ratios &lt;- lm(gave ~ ratio1 + ratio2 + ratio3, data = treat_df) \ntidy(model_ratios)\n\n# A tibble: 4 × 5\n  term         estimate std.error statistic   p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)  0.0227     0.00139   16.3     9.44e-60\n2 ratio1      -0.00198    0.00197   -1.01    3.13e- 1\n3 ratio2      -0.000100   0.00197   -0.0508  9.59e- 1\n4 ratio3      NA         NA         NA      NA       \n\n\n\n\nInterpretation\nThe regression estimates the difference in donation probability across different match ratios using ratio1 (1:1), ratio2 (2:1), and ratio3 (3:1) as indicator variables. The omitted category (baseline) is ratio1, so the coefficients on ratio2 and ratio3 represent the difference relative to the 1:1 match.\nThe results show that neither ratio2 nor ratio3 has a statistically significant effect on the probability of donating compared to ratio1. This means that increasing the match from 1:1 to 2:1 or 3:1 does not significantly boost the likelihood of donation.\nThese findings align with the authors’ conclusion that larger match ratios did not have additional impact — it’s the presence of a match that matters more than how generous it is.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations? ::: {.cell}\nmatch_rates &lt;- df %&gt;%\nfilter(treatment == 1) %&gt;%\ngroup_by(ratio) %&gt;%\nsummarise(response_rate = mean(gave, na.rm = TRUE))\n\nmatch_rates \n\n# A tibble: 3 × 2\n  ratio     response_rate\n  &lt;dbl+lbl&gt;         &lt;dbl&gt;\n1 1                0.0207\n2 2                0.0226\n3 3                0.0227\n\n:::\n\ndiff_2_1_vs_1_1 &lt;- match_rates$response_rate[match_rates$ratio == 2] -\n                   match_rates$response_rate[match_rates$ratio == 1]\n\ndiff_3_1_vs_2_1 &lt;- match_rates$response_rate[match_rates$ratio == 3] -\n                   match_rates$response_rate[match_rates$ratio == 2]\n\ndiff_2_1_vs_1_1\n\n[1] 0.001884251\n\ndiff_3_1_vs_2_1\n\n[1] 0.000100024\n\n\n\ncoef_diff_2_1_vs_1_1 &lt;- coef(model_ratios)[\"ratio2\"] - coef(model_ratios)[\"ratio1\"]\ncoef_diff_3_1_vs_2_1 &lt;- coef(model_ratios)[\"ratio3\"] - coef(model_ratios)[\"ratio2\"]\n\ncoef_diff_2_1_vs_1_1\n\n     ratio2 \n0.001884251 \n\ncoef_diff_3_1_vs_2_1\n\nratio3 \n    NA \n\n\n\n\nInterpretation\nFrom the direct data comparison:\n\nThe increase in donation rate from a 1:1 to 2:1 match is approximately 0.00188 (or 0.188 percentage points)\nThe increase from 2:1 to 3:1 is only 0.00010 (or 0.01 percentage points)\n\nFrom the regression model:\n\nThe difference between the estimated effects of 2:1 and 1:1 is also 0.00188, confirming consistency with the observed data\nThe difference between 3:1 and 2:1 could not be calculated (NA), likely because the 3:1 dummy variable was excluded due to perfect multicollinearity or zero variance\n\nOverall, these results suggest that increasing the match ratio from 1:1 to 2:1 has a minimal impact, and increasing it from 2:1 to 3:1 has virtually no additional effect.\nThis supports Karlan & List’s claim that larger match ratios do not meaningfully boost participation — donors are motivated by the presence of a match, but not by how large it is.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\ntidy(t.test(amount ~ treatment, data = df)) \n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1   -0.154     0.813     0.967     -1.92  0.0551    36216.   -0.311   0.00334\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\n\n\nSize of Charitable Contribution (Conditional on Donating)\nNext, we restrict the data to only those who actually donated (gave == 1) to see if treatment affected how much people gave.\n\ndf_donors &lt;- df %&gt;% filter(gave == 1) \ntidy(t.test(amount ~ treatment, data = df_donors)) \n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     1.67      45.5      43.9     0.585   0.559      557.    -3.94      7.27\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\n\nlibrary(ggplot2) \nlibrary(dplyr) \ndf_donors &lt;- df_donors %&gt;% mutate(group = ifelse(treatment == 1, \"Treatment\", \"Control\")) \nmean_donations &lt;- df_donors %&gt;% \ngroup_by(group) %&gt;% \nsummarise(avg = mean(amount), .groups = \"drop\") \ndf_donors &lt;- df_donors %&gt;% \n    left_join(mean_donations, by = \"group\") \nggplot(df_donors, aes(x = amount)) + \ngeom_histogram( binwidth = 5, aes(fill = group), color = \"black\", alpha = 0.7 ) + \ngeom_vline(aes(xintercept = avg), color = \"red\", linetype = \"dashed\", linewidth = 1) + \nfacet_wrap(~group, ncol = 2) + \nscale_fill_manual(values = c(\"Treatment\" = \"#69b3a2\", \"Control\" = \"#f8766d\")) + \nlabs( title = \"Distribution of Donation Amounts Among Donors\", x = \"Donation Amount\", y = \"Number of Donors\" ) + \ntheme_minimal() + \ntheme( plot.title = element_text(hjust = 0.5, face = \"bold\", size = 14), strip.text = element_text(size = 12, face = \"bold\") ) \n\n\n\n\n\n\n\n\n\n\nInterpretation\nWhen considering all individuals (including non-donors), the treatment group gave slightly more on average, but the difference is not statistically significant. This suggests that offering a match may slightly raise the total dollars raised per person, but the effect is modest when averaged over the full sample.\nWhen we restrict to only those who actually donated, we again see that the average donation size is similar across groups. The regression coefficient on treatment is small and statistically insignificant.\nThe histogram confirms that the donation distributions are quite similar between the treatment and control groups. Most donations cluster around the same range, and the average donation (marked with a red dashed line) is nearly identical across conditions.\nConclusion: The main effect of the treatment was to increase the number of donors — not the amount given by each donor. While total revenue increases with treatment, it’s driven by more people giving, not larger individual donations."
  },
  {
    "objectID": "projects/project2/hw1_questions.html#simulation-experiment",
    "href": "projects/project2/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nTo better understand the behavior of the t-statistic, we use simulation to illustrate the Law of Large Numbers (LLN). This shows how repeated random samples can help us estimate the true mean difference between treatment and control groups.\nWe simulate: - Control group: Bernoulli(p = 0.018) - Treatment group: Bernoulli(p = 0.022) - We draw 100,000 values and plot the running average of the difference\n\nset.seed(123) \ncontrol_sim &lt;- rbinom(100000, 1, 0.018) \ntreat_sim &lt;- rbinom(100000, 1, 0.022) \ndiffs &lt;- treat_sim - control_sim[1:100000] \ncum_avg &lt;- cumsum(diffs) / seq_along(diffs) \nlibrary(ggplot2) \ndf_sim &lt;- data.frame( Simulations = 1:100000, CumulativeAverage = cum_avg ) \nggplot(df_sim, aes(x = Simulations)) + \ngeom_line(aes(y = CumulativeAverage, color = \"Observed Average\"), linewidth = 1) + \ngeom_hline(aes(yintercept = 0.004, color = \"True Mean Difference\"), linetype = \"dashed\", linewidth = 1) + \nscale_color_manual( values = c(\"Observed Average\" = \"#0073C2\", \"True Mean Difference\" = \"#D7263D\") ) + \nlabs( title = \"Law of Large Numbers: Convergence of Mean Difference\", x = \"Number of Simulations\", y = \"Cumulative Average Difference\" ) + \ntheme_minimal(base_size = 14) + \ntheme( plot.title = element_text(hjust = 0.5, face = \"bold\"), legend.position = \"top\" )\n\n\n\n\n\n\n\n\n\n\nInterpretation\nThe graph above demonstrates that as the number of simulated respondents grows, the average difference in donation rates between groups stabilizes near the true difference of 0.004. The blue line represents the cumulative average, and the red dashed line shows the expected population-level difference.\nThis simulation illustrates the Law of Large Numbers in action: with more data points, our estimate of the mean becomes increasingly accurate. It also reinforces the intuition behind statistical tests — they’re more reliable when sample sizes are large because the estimates converge to the truth.\n\n\nCentral Limit Theorem\nTo demonstrate how the sampling distribution of the mean behaves with different sample sizes, we simulate average donation rate differences for the control and treatment groups. We simulate 1,000 experiments for each sample size and visualize the resulting sampling distributions.\n\nset.seed(42)\n\nsample_sizes &lt;- c(50, 200, 500, 1000)\n\ntrue_diff &lt;- 0.022 - 0.018\n\npar(mfrow = c(2, 2))\n\nfor (n in sample_sizes) {\n    diffs &lt;- replicate(1000, {\n    control &lt;- rbinom(n, 1, 0.018)\n    treatment &lt;- rbinom(n, 1, 0.022)\n    mean(treatment) - mean(control)\n})\n\nhist(diffs,\n    breaks = 30,\n    col = \"#A6CEE3\",\n    border = \"#1F78B4\",\n    main = paste(\"Sample Size:\", n),\n    xlab = \"Average (Treatment - Control)\")\n\nabline(v = 0, col = \"black\", lty = 2)\nabline(v = true_diff, col = \"#E31A1C\", lty = 2)\n\nlegend(\"topright\",\n        legend = sprintf(\"True Diff = %.4f\", true_diff),\n        col = \"#E31A1C\",\n        lty = 2,\n        bty = \"n\")\n}\n\n\n\n\n\n\n\n\n\n\nInterpretation\nEach histogram above shows the sampling distribution of the difference in average donation rates for a given sample size, using 1,000 repeated simulations.\n\nFor n = 50, the distribution is wide and irregular, with many simulations near zero, showing high variability.\nAs sample sizes increase (n = 200, 500), the distribution begins to resemble a bell shape and centers more consistently around the true mean difference.\nBy n = 1000, the shape is sharply peaked and tightly centered around the expected value of 0.004.\n\nThis simulation confirms the Central Limit Theorem: even though the underlying data are binary, the distribution of the sample mean becomes more normal and stable as the number of observations grows. The takeaway is clear — with enough data, our estimates become far more reliable."
  }
]